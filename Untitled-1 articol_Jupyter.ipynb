{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833851df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529453f0",
   "metadata": {},
   "source": [
    "in articol cu magenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae87dd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3220' max='3220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3220/3220 40:45, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>0.193291</td>\n",
       "      <td>0.934661</td>\n",
       "      <td>0.934611</td>\n",
       "      <td>0.934485</td>\n",
       "      <td>0.934838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.148900</td>\n",
       "      <td>0.226491</td>\n",
       "      <td>0.942697</td>\n",
       "      <td>0.942509</td>\n",
       "      <td>0.944124</td>\n",
       "      <td>0.941845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3220, training_loss=0.20536921687007692, metrics={'train_runtime': 2445.5377, 'train_samples_per_second': 21.064, 'train_steps_per_second': 1.317, 'total_flos': 5082713589680640.0, 'train_loss': 0.20536921687007692, 'epoch': 2.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "# 1) Load dataset\n",
    "ds = load_dataset(\"raquiba/Sarcasm_News_Headline\")\n",
    "\n",
    "# 2) Create a validation split if missing\n",
    "if \"validation\" not in ds:\n",
    "    split = ds[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "    ds[\"train\"], ds[\"validation\"] = split[\"train\"], split[\"test\"]\n",
    "\n",
    "# 3) Model & tokenizer\n",
    "model_name = \"roberta-base\"\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# 4) Tokenize\n",
    "def tokenize(batch):\n",
    "    return tok(batch[\"headline\"], truncation=True, padding=\"max_length\", max_length=192)\n",
    "\n",
    "ds = ds.map(tokenize, batched=True)\n",
    "\n",
    "# 5) Rename label column to 'labels' and keep only necessary cols\n",
    "for split in ds.keys():\n",
    "    if \"is_sarcastic\" in ds[split].column_names:\n",
    "        ds[split] = ds[split].rename_column(\"is_sarcastic\", \"labels\")\n",
    "\n",
    "keep_cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "if \"token_type_ids\" in ds[\"train\"].column_names:\n",
    "    keep_cols.append(\"token_type_ids\")\n",
    "\n",
    "for split in ds.keys():\n",
    "    drop = [c for c in ds[split].column_names if c not in keep_cols]\n",
    "    ds[split] = ds[split].remove_columns(drop)\n",
    "\n",
    "# 6) Training args — strategies must match when load_best_model_at_end=True\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"out\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=2,\n",
    "    eval_strategy=\"epoch\",   # <- correct key\n",
    "    save_strategy=\"epoch\",         # <- match evaluation strategy\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    logging_steps=50,\n",
    ")\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_recall_fscore_support\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(labels, preds, average=\"macro\", zero_division=0)\n",
    "    return {\"accuracy\": acc, \"macro_f1\": f1, \"precision_macro\": p, \"recall_macro\": r}\n",
    "# 7) Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c52835b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow, two hours of my life I’ll never get back — 10/10 would recommend!\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.094, sarcastic: 0.906}\n",
      "Oscar-worthy performances… if the award is for ‘Best Way to Fall Asleep in 5 Minutes’.\n",
      "  -> pred: non-sarcastic | probs: {non-sarcastic: 0.995, sarcastic: 0.005}\n",
      "I laughed, I cried… mostly because it was painfully bad.\n",
      "  -> pred: non-sarcastic | probs: {non-sarcastic: 0.998, sarcastic: 0.002}\n",
      "Finally, a movie that makes watching paint dry feel exciting.\n",
      "  -> pred: non-sarcastic | probs: {non-sarcastic: 0.998, sarcastic: 0.002}\n",
      "The CGI was so realistic I almost believed those were actual cardboard cutouts.\n",
      "  -> pred: non-sarcastic | probs: {non-sarcastic: 0.997, sarcastic: 0.003}\n",
      "If you love plot holes, bad acting, and awkward pauses, this is your masterpiece.\n",
      "  -> pred: non-sarcastic | probs: {non-sarcastic: 0.999, sarcastic: 0.001}\n",
      "I was on the edge of my seat… trying to find the remote to turn it off.\n",
      "  -> pred: non-sarcastic | probs: {non-sarcastic: 0.990, sarcastic: 0.010}\n",
      "A cinematic tour de force in making the audience question their life choices.\n",
      "  -> pred: non-sarcastic | probs: {non-sarcastic: 0.998, sarcastic: 0.002}\n",
      "The soundtrack really stood out — probably because it was better than everything else.\n",
      "  -> pred: non-sarcastic | probs: {non-sarcastic: 0.998, sarcastic: 0.002}\n",
      "A gripping reminder that trailers can be better than the movie.\n",
      "  -> pred: non-sarcastic | probs: {non-sarcastic: 0.999, sarcastic: 0.001}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "trainer.model.eval()\n",
    "id2label = {0: \"non-sarcastic\", 1: \"sarcastic\"}\n",
    "\n",
    "texts = [\n",
    "\n",
    "\"Wow, two hours of my life I’ll never get back — 10/10 would recommend!\",\n",
    "\n",
    "\"Oscar-worthy performances… if the award is for ‘Best Way to Fall Asleep in 5 Minutes’.\",\n",
    "\n",
    "\"I laughed, I cried… mostly because it was painfully bad.\",\n",
    "\n",
    "\"Finally, a movie that makes watching paint dry feel exciting.\",\n",
    "\n",
    "\"The CGI was so realistic I almost believed those were actual cardboard cutouts.\",\n",
    "\n",
    "\"If you love plot holes, bad acting, and awkward pauses, this is your masterpiece.\",\n",
    "\n",
    "\"I was on the edge of my seat… trying to find the remote to turn it off.\",\n",
    "\n",
    "\"A cinematic tour de force in making the audience question their life choices.\",\n",
    "\n",
    "\"The soundtrack really stood out — probably because it was better than everything else.\",\n",
    "\n",
    "\"A gripping reminder that trailers can be better than the movie.\"\n",
    "]\n",
    "\n",
    "enc = tok(texts, padding=True, truncation=True, max_length=192, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = trainer.model(**{k: v.to(trainer.model.device) for k, v in enc.items()}).logits\n",
    "probs = F.softmax(logits, dim=-1)\n",
    "pred_ids = probs.argmax(-1).tolist()\n",
    "\n",
    "for t, pid, p in zip(texts, pred_ids, probs.tolist()):\n",
    "    print(f\"{t}\\n  -> pred: {id2label[pid]} | probs: {{non-sarcastic: {p[0]:.3f}, sarcastic: {p[1]:.3f}}}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f423af75",
   "metadata": {},
   "source": [
    "fara sarcasm, oricum la arulare a gasit 8 din 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12247c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ironic files found: 437 | Regular files found: 817\n",
      "Built 0 examples from pairing.txt | missing_pairs=0, missing_singles=0\n",
      "Pairing produced few/zero matches. Falling back to 'all files in Ironic/Regular'.\n",
      "Total rows after fallback: 1254\n",
      "                  fname                                               text  \\\n",
      "0  10_11_r1o7rldlvicklm  <STARS>5.0</STARS>\\n<TITLE>Deeply Moved</TITLE...   \n",
      "1  10_18_r30tk050962dzv  <STARS>1.0</STARS>\\n<TITLE>Farce as tragedy</T...   \n",
      "2   10_2_r3m2qqalunt0nk  <STARS>1.0</STARS>\\n<TITLE>Horror and Mortal T...   \n",
      "3   10_6_r222oq5hmg8iw6  <STARS>1.0</STARS>\\n<TITLE>Another timely book...   \n",
      "4   10_7_r1ixyqnnhr3z0k  <STARS>3.0</STARS>\\n<TITLE>Not complete withou...   \n",
      "\n",
      "   label                    group  \n",
      "0      1  ir_10_11_r1o7rldlvicklm  \n",
      "1      1  ir_10_18_r30tk050962dzv  \n",
      "2      1   ir_10_2_r3m2qqalunt0nk  \n",
      "3      1   ir_10_6_r222oq5hmg8iw6  \n",
      "4      1   ir_10_7_r1ixyqnnhr3z0k   \n",
      "Counts:\n",
      " label\n",
      "0    817\n",
      "1    437\n",
      "Name: count, dtype: int64\n",
      "Split sizes: 1015 126 113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a7be6711624a15ab93dd2f5aa4dcc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1015 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5d37dd3f8d45f68b53744c621bc430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/126 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d583ed6bc4fc4b42bdca7548065804b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baraa\\AppData\\Local\\Temp\\ipykernel_23344\\3639007095.py:223: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 15:58, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.609300</td>\n",
       "      <td>0.359415</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.865260</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.849044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.364100</td>\n",
       "      <td>0.302740</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.880163</td>\n",
       "      <td>0.883951</td>\n",
       "      <td>0.876919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2523358464241028, 'eval_accuracy': 0.9026548672566371, 'eval_macro_f1': 0.8952734012974977, 'eval_precision_macro': 0.8873517786561265, 'eval_recall_macro': 0.9074844074844075, 'eval_runtime': 5.4654, 'eval_samples_per_second': 20.676, 'eval_steps_per_second': 0.732, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "# pip install datasets transformers requests scikit-learn pandas\n",
    "import os, re, shutil, subprocess, requests\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 0) Config & URLs ---\n",
    "BASE_URL = \"https://raw.githubusercontent.com/ef2020/SarcasmAmazonReviewsCorpus/master/\"\n",
    "FILES = [\"Ironic.rar\", \"Regular.rar\", \"file_pairing.txt\"]  # (sarcasm_lines.txt optional)\n",
    "DATA_DIR = Path(\"sarcasm_amazon_data\")\n",
    "EXTRACT_DIR = DATA_DIR / \"extracted\"\n",
    "IRONIC_DIR = EXTRACT_DIR / \"Ironic\"\n",
    "REGULAR_DIR = EXTRACT_DIR / \"Regular\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True); EXTRACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- 1) Download archives & pairing file ---\n",
    "def download(url: str, out_path: Path):\n",
    "    if out_path.exists(): return\n",
    "    r = requests.get(url, timeout=120); r.raise_for_status()\n",
    "    out_path.write_bytes(r.content)\n",
    "\n",
    "for fname in FILES:\n",
    "    download(BASE_URL + fname, DATA_DIR / fname)\n",
    "\n",
    "# --- 2) Extract .rar archives via 7-Zip (robust) ---\n",
    "def _find_7z() -> str:\n",
    "    p = shutil.which(\"7z\")\n",
    "    if p: return p\n",
    "    for c in [r\"C:\\Program Files\\7-Zip\\7z.exe\",\n",
    "              r\"C:\\Program Files (x86)\\7-Zip\\7z.exe\",\n",
    "              \"/usr/bin/7z\", \"/usr/local/bin/7z\", \"/opt/homebrew/bin/7z\"]:\n",
    "        if Path(c).exists(): return c\n",
    "    p = os.environ.get(\"SEVENZ_PATH\")\n",
    "    if p and Path(p).exists(): return p\n",
    "    raise FileNotFoundError(\n",
    "        \"7z not found. Install 7-Zip and add to PATH, or set SEVENZ_PATH.\\n\"\n",
    "        \"Windows: winget install 7zip.7zip\"\n",
    "    )\n",
    "\n",
    "def extract_with_7z(rar_path: Path, out_dir: Path):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    # skip if there are already .txt files somewhere under out_dir\n",
    "    if list(out_dir.rglob(\"*.txt\")): return\n",
    "    sevenz = _find_7z()\n",
    "    cmd = [sevenz, \"x\", str(rar_path), f\"-o{out_dir}\", \"-y\"]\n",
    "    res = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if res.returncode != 0:\n",
    "        raise RuntimeError(f\"7z failed for {rar_path}\\nSTDERR:\\n{res.stderr[:400]}\")\n",
    "\n",
    "extract_with_7z(DATA_DIR / \"Ironic.rar\", IRONIC_DIR)\n",
    "extract_with_7z(DATA_DIR / \"Regular.rar\", REGULAR_DIR)\n",
    "\n",
    "# --- 3) Read reviews (recursive) ---\n",
    "def read_txt_dir_recursive(d: Path):\n",
    "    out = {}\n",
    "    for fp in d.rglob(\"*.txt\"):\n",
    "        try:\n",
    "            txt = fp.read_text(encoding=\"utf-8\", errors=\"ignore\").strip()\n",
    "        except UnicodeDecodeError:\n",
    "            txt = fp.read_text(errors=\"ignore\").strip()\n",
    "        out[fp.name] = txt\n",
    "    return out\n",
    "\n",
    "ironic_raw  = read_txt_dir_recursive(IRONIC_DIR)\n",
    "regular_raw = read_txt_dir_recursive(REGULAR_DIR)\n",
    "print(f\"Ironic files found: {len(ironic_raw)} | Regular files found: {len(regular_raw)}\")\n",
    "\n",
    "# Build normalized lookup: key = lowercase basename without extension\n",
    "def norm_key(name: str) -> str:\n",
    "    base = Path(name).name\n",
    "    return re.sub(r\"\\.txt$\", \"\", base, flags=re.I).lower()\n",
    "\n",
    "ironic = {norm_key(k): v for k, v in ironic_raw.items()}\n",
    "regular = {norm_key(k): v for k, v in regular_raw.items()}\n",
    "\n",
    "# --- 4) Parse file_pairing.txt using normalized names ---\n",
    "pairing_txt = (DATA_DIR / \"file_pairing.txt\").read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "pairs, singles = [], []\n",
    "for line in pairing_txt.splitlines():\n",
    "    line = line.strip()\n",
    "    if not line: continue\n",
    "    if line.upper().startswith(\"PAIRS:\"):\n",
    "        fns = re.findall(r\"([A-Za-z0-9_\\-]+\\.txt)\", line)\n",
    "        if len(fns) >= 2:\n",
    "            pairs.append((norm_key(fns[0]), norm_key(fns[1])))\n",
    "    elif line.upper().startswith(\"IRONIC:\"):\n",
    "        fns = re.findall(r\"([A-Za-z0-9_\\-]+\\.txt)\", line)\n",
    "        if fns:\n",
    "            singles.append((norm_key(fns[0]), 1))\n",
    "    elif line.upper().startswith(\"REGULAR:\"):\n",
    "        fns = re.findall(r\"([A-Za-z0-9_\\-]+\\.txt)\", line)\n",
    "        if fns:\n",
    "            singles.append((norm_key(fns[0]), 0))\n",
    "\n",
    "# --- 5) Build rows; track mismatches for debugging ---\n",
    "rows = []\n",
    "missing_pairs, missing_singles = 0, 0\n",
    "group_id = 0\n",
    "\n",
    "for fi, fr in pairs:\n",
    "    ti, tr = ironic.get(fi), regular.get(fr)\n",
    "    if ti is not None and tr is not None:\n",
    "        rows.append({\"fname\": fi, \"text\": ti, \"label\": 1, \"group\": f\"pair_{group_id}\"})\n",
    "        rows.append({\"fname\": fr, \"text\": tr, \"label\": 0, \"group\": f\"pair_{group_id}\"})\n",
    "        group_id += 1\n",
    "    else:\n",
    "        missing_pairs += 1\n",
    "\n",
    "for fn, lab in singles:\n",
    "    if lab == 1:\n",
    "        t = ironic.get(fn)\n",
    "        if t is not None:\n",
    "            rows.append({\"fname\": fn, \"text\": t, \"label\": 1, \"group\": f\"single_{fn}\"})\n",
    "        else:\n",
    "            missing_singles += 1\n",
    "    else:\n",
    "        t = regular.get(fn)\n",
    "        if t is not None:\n",
    "            rows.append({\"fname\": fn, \"text\": t, \"label\": 0, \"group\": f\"single_{fn}\"})\n",
    "        else:\n",
    "            missing_singles += 1\n",
    "\n",
    "print(f\"Built {len(rows)} examples from pairing.txt | missing_pairs={missing_pairs}, missing_singles={missing_singles}\")\n",
    "\n",
    "# Fallback: if pairing produced nothing (or very few), just take all files\n",
    "if len(rows) < 50:\n",
    "    print(\"Pairing produced few/zero matches. Falling back to 'all files in Ironic/Regular'.\")\n",
    "    rows = []\n",
    "    for k, v in ironic.items():\n",
    "        rows.append({\"fname\": k, \"text\": v, \"label\": 1, \"group\": f\"ir_{k}\"})\n",
    "    for k, v in regular.items():\n",
    "        rows.append({\"fname\": k, \"text\": v, \"label\": 0, \"group\": f\"reg_{k}\"})\n",
    "    print(f\"Total rows after fallback: {len(rows)}\")\n",
    "\n",
    "# --- 6) DataFrame & splits ---\n",
    "df = pd.DataFrame(rows)\n",
    "if \"text\" not in df.columns or df.empty:\n",
    "    raise RuntimeError(\n",
    "        \"No review texts assembled. Check that extraction created .txt files and that file_pairing names \"\n",
    "        \"match extracted filenames. Print a few keys:\\n\"\n",
    "        f\"  Ironic keys sample: {list(list(ironic.keys())[:5])}\\n\"\n",
    "        f\"  Regular keys sample: {list(list(regular.keys())[:5])}\"\n",
    "    )\n",
    "\n",
    "print(df.head(), \"\\nCounts:\\n\", df[\"label\"].value_counts())\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "gss = GroupShuffleSplit(test_size=0.1, n_splits=1, random_state=42)\n",
    "train_idx, val_idx = next(gss.split(df, groups=df[\"group\"]))\n",
    "df_train = df.iloc[train_idx].reset_index(drop=True)\n",
    "df_val   = df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "# Optional test split from train\n",
    "gss2 = GroupShuffleSplit(test_size=0.1, n_splits=1, random_state=123)\n",
    "tr_idx, te_idx = next(gss2.split(df_train, groups=df_train[\"group\"]))\n",
    "df_test  = df_train.iloc[te_idx].reset_index(drop=True)\n",
    "df_train = df_train.iloc[tr_idx].reset_index(drop=True)\n",
    "print(\"Split sizes:\", len(df_train), len(df_val), len(df_test))\n",
    "\n",
    "# --- 7) HF DatasetDict ---\n",
    "from datasets import Dataset, DatasetDict\n",
    "def to_hfds(dframe: pd.DataFrame) -> Dataset:\n",
    "    return Dataset.from_pandas(dframe[[\"text\", \"label\"]], preserve_index=False)\n",
    "\n",
    "hf_ds = DatasetDict({\n",
    "    \"train\": to_hfds(df_train),\n",
    "    \"validation\": to_hfds(df_val),\n",
    "    \"test\": to_hfds(df_test)\n",
    "})\n",
    "\n",
    "# --- 8) Tokenize & fine-tune RoBERTa ---\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "#model_name = \"roberta-base\"\n",
    "#model_name = \"microsoft/deberta-v3-base\"\n",
    "#model_name = \"microsoft/deberta-v3-large\"\n",
    "#model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model_name = \"roberta-large\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "id2label = {0: \"non-sarcastic\", 1: \"sarcastic\"}\n",
    "label2id = {\"non-sarcastic\": 0, \"sarcastic\": 1}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=2, id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tok(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=192)\n",
    "\n",
    "hf_ds = hf_ds.map(tokenize, batched=True)\n",
    "\n",
    "cols = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "if \"token_type_ids\" in hf_ds[\"train\"].column_names:\n",
    "    cols.append(\"token_type_ids\")\n",
    "for split in hf_ds.keys():\n",
    "    drops = [c for c in hf_ds[split].column_names if c not in cols]\n",
    "    hf_ds[split] = hf_ds[split].remove_columns(drops)\n",
    "    hf_ds[split] = hf_ds[split].rename_column(\"label\", \"labels\")\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_recall_fscore_support\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(labels, preds, average=\"macro\", zero_division=0)\n",
    "    return {\"accuracy\": acc, \"macro_f1\": f1, \"precision_macro\": p, \"recall_macro\": r}\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"out\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=2,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    greater_is_better=True,\n",
    "    logging_steps=50,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=hf_ds[\"train\"],\n",
    "    eval_dataset=hf_ds[\"validation\"],\n",
    "    tokenizer=tok,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "print(trainer.evaluate(hf_ds[\"test\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e740bd",
   "metadata": {},
   "source": [
    "cu FILES = [\"Ironic.rar\", \"Regular.rar\", \"file_pairing.txt\", \"sarcasm_lines.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50e0f118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ironic files found: 437 | Regular files found: 817\n",
      "Built 0 examples from pairing.txt | missing_pairs=0, missing_singles=0\n",
      "Pairing produced few/zero matches. Falling back to 'all files in Ironic/Regular'.\n",
      "Total rows after fallback: 1254\n",
      "Appended 436 sarcastic lines from sarcasm_lines.txt (deduped).\n",
      "                     fname                                               text  \\\n",
      "0  sarcasm_line_000276.txt  36_16_R1D5KMCO7KVUGQ\\t\"This band is like soooo...   \n",
      "1     44_12_r3n66hkdbdzqeo  <STARS>1.0</STARS>\\n<TITLE>Not even worth fini...   \n",
      "2      13_9_r1ypfgq15rj8hx  <STARS>5.0</STARS>\\n<TITLE>A series you just h...   \n",
      "3     17_18_r3w387ntmcsmpp  <STARS>3.0</STARS>\\n<TITLE>Warning: Instructio...   \n",
      "4     24_13_r3juqa0325ok1l  <STARS>1.0</STARS>\\n<TITLE>Husband A Huge Croo...   \n",
      "\n",
      "   label                     group  \n",
      "0      1              sline_000276  \n",
      "1      0  reg_44_12_r3n66hkdbdzqeo  \n",
      "2      0   reg_13_9_r1ypfgq15rj8hx  \n",
      "3      1   ir_17_18_r3w387ntmcsmpp  \n",
      "4      1   ir_24_13_r3juqa0325ok1l   \n",
      "Counts:\n",
      " label\n",
      "1    873\n",
      "0    817\n",
      "Name: count, dtype: int64\n",
      "Split sizes: 1368 169 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\baraa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1875abd1fa14e2b989106648a7defb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef685ac265a4447a6d4cc0eb938d534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/169 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24653eef83fd431f94006fc7fb10577e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/153 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ecc1cd63b9c4032aac4cffcbc0b920d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/172 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.506, 'grad_norm': 2.9296886920928955, 'learning_rate': 1.4186046511627909e-05, 'epoch': 0.58}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef6ed60f04a4f4b931ee77d3d98e248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33323904871940613, 'eval_accuracy': 0.8520710059171598, 'eval_macro_f1': 0.8519880889823086, 'eval_precision_macro': 0.852759876716167, 'eval_recall_macro': 0.8541490857946554, 'eval_runtime': 25.0373, 'eval_samples_per_second': 6.75, 'eval_steps_per_second': 0.24, 'epoch': 1.0}\n",
      "{'loss': 0.2873, 'grad_norm': 2.794153928756714, 'learning_rate': 8.372093023255815e-06, 'epoch': 1.16}\n",
      "{'loss': 0.2701, 'grad_norm': 6.873016834259033, 'learning_rate': 2.558139534883721e-06, 'epoch': 1.74}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd694d21a7d452991998cc9dab23ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3408583998680115, 'eval_accuracy': 0.863905325443787, 'eval_macro_f1': 0.8639053254437871, 'eval_precision_macro': 0.8675808720112518, 'eval_recall_macro': 0.8675808720112518, 'eval_runtime': 24.9623, 'eval_samples_per_second': 6.77, 'eval_steps_per_second': 0.24, 'epoch': 2.0}\n",
      "{'train_runtime': 491.0483, 'train_samples_per_second': 5.572, 'train_steps_per_second': 0.35, 'train_loss': 0.33398787919865097, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9a2915ede54386a910cd5ab12f72ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24018637835979462, 'eval_accuracy': 0.9215686274509803, 'eval_macro_f1': 0.9209982788296041, 'eval_precision_macro': 0.9209982788296041, 'eval_recall_macro': 0.9209982788296041, 'eval_runtime': 23.3517, 'eval_samples_per_second': 6.552, 'eval_steps_per_second': 0.214, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "# pip install datasets transformers requests scikit-learn pandas\n",
    "import os, re, shutil, subprocess, requests, random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 0) Config & URLs ---\n",
    "BASE_URL = \"https://raw.githubusercontent.com/ef2020/SarcasmAmazonReviewsCorpus/master/\"\n",
    "FILES = [\"Ironic.rar\", \"Regular.rar\", \"file_pairing.txt\", \"sarcasm_lines.txt\"]\n",
    "DATA_DIR = Path(\"sarcasm_amazon_data\")\n",
    "EXTRACT_DIR = DATA_DIR / \"extracted\"\n",
    "IRONIC_DIR = EXTRACT_DIR / \"Ironic\"\n",
    "REGULAR_DIR = EXTRACT_DIR / \"Regular\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True); EXTRACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- 1) Download archives & pairing file ---\n",
    "def download(url: str, out_path: Path):\n",
    "    if out_path.exists(): return\n",
    "    r = requests.get(url, timeout=120); r.raise_for_status()\n",
    "    out_path.write_bytes(r.content)\n",
    "\n",
    "for fname in FILES:\n",
    "    download(BASE_URL + fname, DATA_DIR / fname)\n",
    "\n",
    "# --- 2) Extract .rar archives via 7-Zip (robust) ---\n",
    "def _find_7z() -> str:\n",
    "    p = shutil.which(\"7z\")\n",
    "    if p: return p\n",
    "    for c in [r\"C:\\Program Files\\7-Zip\\7z.exe\",\n",
    "              r\"C:\\Program Files (x86)\\7-Zip\\7z.exe\",\n",
    "              \"/usr/bin/7z\", \"/usr/local/bin/7z\", \"/opt/homebrew/bin/7z\"]:\n",
    "        if Path(c).exists(): return c\n",
    "    p = os.environ.get(\"SEVENZ_PATH\")\n",
    "    if p and Path(p).exists(): return p\n",
    "    raise FileNotFoundError(\n",
    "        \"7z not found. Install 7-Zip and add to PATH, or set SEVENZ_PATH.\\n\"\n",
    "        \"Windows: winget install 7zip.7zip\"\n",
    "    )\n",
    "\n",
    "def extract_with_7z(rar_path: Path, out_dir: Path):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    if list(out_dir.rglob(\"*.txt\")): return\n",
    "    sevenz = _find_7z()\n",
    "    cmd = [sevenz, \"x\", str(rar_path), f\"-o{out_dir}\", \"-y\"]\n",
    "    res = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if res.returncode != 0:\n",
    "        raise RuntimeError(f\"7z failed for {rar_path}\\nSTDERR:\\n{res.stderr[:400]}\")\n",
    "\n",
    "extract_with_7z(DATA_DIR / \"Ironic.rar\", IRONIC_DIR)\n",
    "extract_with_7z(DATA_DIR / \"Regular.rar\", REGULAR_DIR)\n",
    "\n",
    "# --- 3) Read reviews (recursive) ---\n",
    "def read_txt_dir_recursive(d: Path):\n",
    "    out = {}\n",
    "    for fp in d.rglob(\"*.txt\"):\n",
    "        try:\n",
    "            txt = fp.read_text(encoding=\"utf-8\", errors=\"ignore\").strip()\n",
    "        except UnicodeDecodeError:\n",
    "            txt = fp.read_text(errors=\"ignore\").strip()\n",
    "        out[fp.name] = txt\n",
    "    return out\n",
    "\n",
    "ironic_raw  = read_txt_dir_recursive(IRONIC_DIR)\n",
    "regular_raw = read_txt_dir_recursive(REGULAR_DIR)\n",
    "print(f\"Ironic files found: {len(ironic_raw)} | Regular files found: {len(regular_raw)}\")\n",
    "\n",
    "# Build normalized lookup: key = lowercase basename without extension\n",
    "def norm_key(name: str) -> str:\n",
    "    base = Path(name).name\n",
    "    return re.sub(r\"\\.txt$\", \"\", base, flags=re.I).lower()\n",
    "\n",
    "# Simple text normalizer for deduplication\n",
    "def norm_text(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", s.strip().lower())\n",
    "\n",
    "ironic = {norm_key(k): v for k, v in ironic_raw.items()}\n",
    "regular = {norm_key(k): v for k, v in regular_raw.items()}\n",
    "\n",
    "# --- 4) Parse file_pairing.txt using normalized names ---\n",
    "pairing_txt = (DATA_DIR / \"file_pairing.txt\").read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "pairs, singles = [], []\n",
    "for line in pairing_txt.splitlines():\n",
    "    line = line.strip()\n",
    "    if not line: continue\n",
    "    if line.upper().startswith(\"PAIRS:\"):\n",
    "        fns = re.findall(r\"([A-Za-z0-9_\\-]+\\.txt)\", line)\n",
    "        if len(fns) >= 2:\n",
    "            pairs.append((norm_key(fns[0]), norm_key(fns[1])))\n",
    "    elif line.upper().startswith(\"IRONIC:\"):\n",
    "        fns = re.findall(r\"([A-Za-z0-9_\\-]+\\.txt)\", line)\n",
    "        if fns:\n",
    "            singles.append((norm_key(fns[0]), 1))\n",
    "    elif line.upper().startswith(\"REGULAR:\"):\n",
    "        fns = re.findall(r\"([A-Za-z0-9_\\-]+\\.txt)\", line)\n",
    "        if fns:\n",
    "            singles.append((norm_key(fns[0]), 0))\n",
    "\n",
    "# --- 5) Build rows; track mismatches for debugging ---\n",
    "rows = []\n",
    "missing_pairs, missing_singles = 0, 0\n",
    "group_id = 0\n",
    "\n",
    "for fi, fr in pairs:\n",
    "    ti, tr = ironic.get(fi), regular.get(fr)\n",
    "    if ti is not None and tr is not None:\n",
    "        rows.append({\"fname\": fi, \"text\": ti, \"label\": 1, \"group\": f\"pair_{group_id}\"})\n",
    "        rows.append({\"fname\": fr, \"text\": tr, \"label\": 0, \"group\": f\"pair_{group_id}\"})\n",
    "        group_id += 1\n",
    "    else:\n",
    "        missing_pairs += 1\n",
    "\n",
    "for fn, lab in singles:\n",
    "    if lab == 1:\n",
    "        t = ironic.get(fn)\n",
    "        if t is not None:\n",
    "            rows.append({\"fname\": fn, \"text\": t, \"label\": 1, \"group\": f\"single_{fn}\"})\n",
    "        else:\n",
    "            missing_singles += 1\n",
    "    else:\n",
    "        t = regular.get(fn)\n",
    "        if t is not None:\n",
    "            rows.append({\"fname\": fn, \"text\": t, \"label\": 0, \"group\": f\"single_{fn}\"})\n",
    "        else:\n",
    "            missing_singles += 1\n",
    "\n",
    "print(f\"Built {len(rows)} examples from pairing.txt | missing_pairs={missing_pairs}, missing_singles={missing_singles}\")\n",
    "\n",
    "# Fallback: if pairing produced nothing (or very few), just take all files\n",
    "if len(rows) < 50:\n",
    "    print(\"Pairing produced few/zero matches. Falling back to 'all files in Ironic/Regular'.\")\n",
    "    rows = []\n",
    "    for k, v in ironic.items():\n",
    "        rows.append({\"fname\": k, \"text\": v, \"label\": 1, \"group\": f\"ir_{k}\"})\n",
    "    for k, v in regular.items():\n",
    "        rows.append({\"fname\": k, \"text\": v, \"label\": 0, \"group\": f\"reg_{k}\"})\n",
    "    print(f\"Total rows after fallback: {len(rows)}\")\n",
    "\n",
    "# --- 5b) ADD sarcasm_lines.txt (label=1), dedupe, then shuffle ---\n",
    "sarcasm_path = DATA_DIR / \"sarcasm_lines.txt\"\n",
    "added = 0\n",
    "if sarcasm_path.exists():\n",
    "    s_txt = sarcasm_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    s_lines = [ln.strip() for ln in s_txt.splitlines() if ln.strip()]\n",
    "    # Build a set of existing normalized texts to avoid duplicates\n",
    "    existing_norms = set(norm_text(r[\"text\"]) for r in rows)\n",
    "    for i, line in enumerate(s_lines):\n",
    "        nline = norm_text(line)\n",
    "        if nline and nline not in existing_norms:\n",
    "            rows.append({\n",
    "                \"fname\": f\"sarcasm_line_{i:06d}.txt\",\n",
    "                \"text\": line,\n",
    "                \"label\": 1,\n",
    "                \"group\": f\"sline_{i:06d}\"     # unique group per line to avoid leakage\n",
    "            })\n",
    "            existing_norms.add(nline)\n",
    "            added += 1\n",
    "    print(f\"Appended {added} sarcastic lines from sarcasm_lines.txt (deduped).\")\n",
    "else:\n",
    "    print(\"sarcasm_lines.txt not found; skipping.\")\n",
    "\n",
    "# Shuffle all rows before making the DataFrame (for good measure; split is group-aware anyway)\n",
    "random.seed(42)\n",
    "random.shuffle(rows)\n",
    "\n",
    "# --- 6) DataFrame & splits ---\n",
    "df = pd.DataFrame(rows)\n",
    "if \"text\" not in df.columns or df.empty:\n",
    "    raise RuntimeError(\n",
    "        \"No review texts assembled. Check that extraction created .txt files and that file_pairing names \"\n",
    "        \"match extracted filenames.\"\n",
    "    )\n",
    "\n",
    "print(df.head(), \"\\nCounts:\\n\", df[\"label\"].value_counts())\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "gss = GroupShuffleSplit(test_size=0.1, n_splits=1, random_state=42)\n",
    "train_idx, val_idx = next(gss.split(df, groups=df[\"group\"]))\n",
    "df_train = df.iloc[train_idx].reset_index(drop=True)\n",
    "df_val   = df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "# Optional test split from train\n",
    "gss2 = GroupShuffleSplit(test_size=0.1, n_splits=1, random_state=123)\n",
    "tr_idx, te_idx = next(gss2.split(df_train, groups=df_train[\"group\"]))\n",
    "df_test  = df_train.iloc[te_idx].reset_index(drop=True)\n",
    "df_train = df_train.iloc[tr_idx].reset_index(drop=True)\n",
    "print(\"Split sizes:\", len(df_train), len(df_val), len(df_test))\n",
    "\n",
    "# --- 7) HF DatasetDict ---\n",
    "from datasets import Dataset, DatasetDict\n",
    "def to_hfds(dframe: pd.DataFrame) -> Dataset:\n",
    "    return Dataset.from_pandas(dframe[[\"text\", \"label\"]], preserve_index=False)\n",
    "\n",
    "hf_ds = DatasetDict({\n",
    "    \"train\": to_hfds(df_train),\n",
    "    \"validation\": to_hfds(df_val),\n",
    "    \"test\": to_hfds(df_test)\n",
    "})\n",
    "\n",
    "# --- 8) Tokenize & fine-tune RoBERTa ---\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "#model_name = \"roberta-base\"\n",
    "#model_name = \"microsoft/deberta-v3-base\"\n",
    "#model_name = \"microsoft/deberta-v3-large\"\n",
    "#model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "#model_name = \"roberta-large\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "id2label = {0: \"non-sarcastic\", 1: \"sarcastic\"}\n",
    "label2id = {\"non-sarcastic\": 0, \"sarcastic\": 1}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=2, id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tok(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=192)\n",
    "\n",
    "hf_ds = hf_ds.map(tokenize, batched=True)\n",
    "\n",
    "cols = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "if \"token_type_ids\" in hf_ds[\"train\"].column_names:\n",
    "    cols.append(\"token_type_ids\")\n",
    "for split in hf_ds.keys():\n",
    "    drops = [c for c in hf_ds[split].column_names if c not in cols]\n",
    "    hf_ds[split] = hf_ds[split].remove_columns(drops)\n",
    "    hf_ds[split] = hf_ds[split].rename_column(\"label\", \"labels\")\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_recall_fscore_support\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(labels, preds, average=\"macro\", zero_division=0)\n",
    "    return {\"accuracy\": acc, \"macro_f1\": f1, \"precision_macro\": p, \"recall_macro\": r}\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"out\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=2,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    greater_is_better=True,\n",
    "    logging_steps=50,\n",
    ")\n",
    "\"\"\"from transformers import TrainingArguments, EarlyStoppingCallback\n",
    "callbacks = [EarlyStoppingCallback(\n",
    "    early_stopping_patience=1,\n",
    "    early_stopping_threshold=1e-3  # ignoră “îmbunătățiri” minuscule ca +0.00009\n",
    ")]\"\"\"\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=hf_ds[\"train\"],\n",
    "    eval_dataset=hf_ds[\"validation\"],\n",
    "    tokenizer=tok,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "print(trainer.evaluate(hf_ds[\"test\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3100b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow, two hours of my life I’ll never get back — 10/10 would recommend!\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.001, sarcastic: 0.999}\n",
      "Oscar-worthy performances… if the award is for ‘Best Way to Fall Asleep in 5 Minutes’.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.001, sarcastic: 0.999}\n",
      "I laughed, I cried… mostly because it was painfully bad.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.006, sarcastic: 0.994}\n",
      "Finally, a movie that makes watching paint dry feel exciting.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.003, sarcastic: 0.997}\n",
      "The CGI was so realistic I almost believed those were actual cardboard cutouts.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.006, sarcastic: 0.994}\n",
      "If you love plot holes, bad acting, and awkward pauses, this is your masterpiece.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.001, sarcastic: 0.999}\n",
      "I was on the edge of my seat… trying to find the remote to turn it off.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.008, sarcastic: 0.992}\n",
      "A cinematic tour de force in making the audience question their life choices.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.001, sarcastic: 0.999}\n",
      "The soundtrack really stood out — probably because it was better than everything else.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.000, sarcastic: 1.000}\n",
      "A gripping reminder that trailers can be better than the movie.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.001, sarcastic: 0.999}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "trainer.model.eval()\n",
    "id2label = {0: \"non-sarcastic\", 1: \"sarcastic\"}\n",
    "\n",
    "texts = [\n",
    "\n",
    "\"Wow, two hours of my life I’ll never get back — 10/10 would recommend!\",\n",
    "\n",
    "\"Oscar-worthy performances… if the award is for ‘Best Way to Fall Asleep in 5 Minutes’.\",\n",
    "\n",
    "\"I laughed, I cried… mostly because it was painfully bad.\",\n",
    "\n",
    "\"Finally, a movie that makes watching paint dry feel exciting.\",\n",
    "\n",
    "\"The CGI was so realistic I almost believed those were actual cardboard cutouts.\",\n",
    "\n",
    "\"If you love plot holes, bad acting, and awkward pauses, this is your masterpiece.\",\n",
    "\n",
    "\"I was on the edge of my seat… trying to find the remote to turn it off.\",\n",
    "\n",
    "\"A cinematic tour de force in making the audience question their life choices.\",\n",
    "\n",
    "\"The soundtrack really stood out — probably because it was better than everything else.\",\n",
    "\n",
    "\"A gripping reminder that trailers can be better than the movie.\"\n",
    "]\n",
    "\n",
    "enc = tok(texts, padding=True, truncation=True, max_length=192, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = trainer.model(**{k: v.to(trainer.model.device) for k, v in enc.items()}).logits\n",
    "probs = F.softmax(logits, dim=-1)\n",
    "pred_ids = probs.argmax(-1).tolist()\n",
    "\n",
    "for t, pid, p in zip(texts, pred_ids, probs.tolist()):\n",
    "    print(f\"{t}\\n  -> pred: {id2label[pid]} | probs: {{non-sarcastic: {p[0]:.3f}, sarcastic: {p[1]:.3f}}}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2816dee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five stars for teaching me patience—only took three hours to load the homepage.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.012, sarcastic: 0.988}\n",
      "Battery life is incredible—dies just from looking at 20%.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.004, sarcastic: 0.996}\n",
      "The ‘noise-cancelling’ headphones work great at cancelling music, not the noise.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.029, sarcastic: 0.971}\n",
      "Our room had a ‘city view’—if you count a brick wall as urban scenery.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.003, sarcastic: 0.997}\n",
      "Customer support was lightning-fast; I blinked and only waited two weeks.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.006, sarcastic: 0.994}\n",
      "The camera’s low-light performance is amazing—you can’t see a thing.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.001, sarcastic: 0.999}\n",
      "Truly intuitive UI; I only needed a PhD and a treasure map.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.002, sarcastic: 0.998}\n",
      "Love the premium build—feels expensive to replace.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.003, sarcastic: 0.997}\n",
      "Great value: you get two features for the price of five.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.005, sarcastic: 0.995}\n",
      "The chef really nailed it—my steak had the same personality as the shoe it resembled.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.002, sarcastic: 0.998}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "trainer.model.eval()\n",
    "id2label = {0: \"non-sarcastic\", 1: \"sarcastic\"}\n",
    "\n",
    "texts = [\n",
    "\"Five stars for teaching me patience—only took three hours to load the homepage.\",\n",
    "\"Battery life is incredible—dies just from looking at 20%.\",\n",
    "\"The ‘noise-cancelling’ headphones work great at cancelling music, not the noise.\",\n",
    "\"Our room had a ‘city view’—if you count a brick wall as urban scenery.\",\n",
    "\"Customer support was lightning-fast; I blinked and only waited two weeks.\",\n",
    "\"The camera’s low-light performance is amazing—you can’t see a thing.\",\n",
    "\"Truly intuitive UI; I only needed a PhD and a treasure map.\",\n",
    "\"Love the premium build—feels expensive to replace.\",\n",
    "\"Great value: you get two features for the price of five.\",\n",
    "\"The chef really nailed it—my steak had the same personality as the shoe it resembled.\"\n",
    "]\n",
    "\n",
    "enc = tok(texts, padding=True, truncation=True, max_length=192, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = trainer.model(**{k: v.to(trainer.model.device) for k, v in enc.items()}).logits\n",
    "probs = F.softmax(logits, dim=-1)\n",
    "pred_ids = probs.argmax(-1).tolist()\n",
    "\n",
    "for t, pid, p in zip(texts, pred_ids, probs.tolist()):\n",
    "    print(f\"{t}\\n  -> pred: {id2label[pid]} | probs: {{non-sarcastic: {p[0]:.3f}, sarcastic: {p[1]:.3f}}}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecb1aaa",
   "metadata": {},
   "source": [
    "\"Perfect for minimalists—comes without the features I actually needed.\",\n",
    "\"Seamless connectivity—disconnects right before you hit connect.\",\n",
    "\"Smells like premium—probably the plastic melting.\",\n",
    "\"Auto-save works great—saves everything except my progress.\",\n",
    "\"Compact design—especially the battery life.\",\n",
    "\"Truly hands-free—because it never responds to touch.\",\n",
    "\"Ergonomic keyboard—if your hands are shaped like question marks.\",\n",
    "\"Water-resistant—tears only, not rain.\",\n",
    "\"Delivers overnight—just not the same night as the order.\",\n",
    "\"Top-tier security—no one, including me, can log in.\",\n",
    "\"Voice assistant understands me—when I say nothing.\",\n",
    "\"The update improved everything—by making sure nothing opens.\",\n",
    "\"Room with natural light—after the sun bounces off the parking lot.\",\n",
    "\"Noise isolation is superb—I couldn’t hear the music at all.\",\n",
    "\"Lag-free gaming—because the game never starts.\",\n",
    "\"Travel pillow so comfy—I stayed awake the entire flight.\",\n",
    "\"Self-cleaning oven—burnt everything to a crisp, problem solved.\",\n",
    "\"Eco mode is powerful—saves energy by not working.\",\n",
    "\"Generous portions—of disappointment.\",\n",
    "\"Shockproof case—phone fainted anyway.\",\n",
    "\"Works out of the box—once you buy the missing parts.\",\n",
    "\"Crystal-clear display—if you enjoy fog.\",\n",
    "\"Fast charging—percentages move at the speed of drama.\",\n",
    "\"Kid-friendly app—my inner child cried.\",\n",
    "\"Five-star dining—the bill, not the food.\",\n",
    "\"The map is so accurate—it led me straight to nowhere.\",\n",
    "\"Bluetooth range is impressive—if you stand exactly next to it.\",\n",
    "\"Build quality feels solid—like a brick with buttons.\",\n",
    "\"The tutorial is intuitive—after the third reread.\",\n",
    "\"Sleek interface—hides the settings you actually need.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3c157b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect for minimalists—comes without the features I actually needed.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.006, sarcastic: 0.994}\n",
      "Seamless connectivity—disconnects right before you hit connect.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.011, sarcastic: 0.989}\n",
      "Smells like premium—probably the plastic melting.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.009, sarcastic: 0.991}\n",
      "Auto-save works great—saves everything except my progress.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.001, sarcastic: 0.999}\n",
      "Compact design—especially the battery life.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.004, sarcastic: 0.996}\n",
      "Truly hands-free—because it never responds to touch.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.002, sarcastic: 0.998}\n",
      "Ergonomic keyboard—if your hands are shaped like question marks.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.015, sarcastic: 0.985}\n",
      "Water-resistant—tears only, not rain.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.002, sarcastic: 0.998}\n",
      "Delivers overnight—just not the same night as the order.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.001, sarcastic: 0.999}\n",
      "Top-tier security—no one, including me, can log in.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.008, sarcastic: 0.992}\n",
      "Voice assistant understands me—when I say nothing.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.002, sarcastic: 0.998}\n",
      "The update improved everything—by making sure nothing opens.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.002, sarcastic: 0.998}\n",
      "Room with natural light—after the sun bounces off the parking lot.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.001, sarcastic: 0.999}\n",
      "Noise isolation is superb—I couldn’t hear the music at all.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.001, sarcastic: 0.999}\n",
      "Lag-free gaming—because the game never starts.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.019, sarcastic: 0.981}\n",
      "Travel pillow so comfy—I stayed awake the entire flight.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.002, sarcastic: 0.998}\n",
      "Self-cleaning oven—burnt everything to a crisp, problem solved.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.034, sarcastic: 0.966}\n",
      "Eco mode is powerful—saves energy by not working.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.003, sarcastic: 0.997}\n",
      "Generous portions—of disappointment.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.008, sarcastic: 0.992}\n",
      "Shockproof case—phone fainted anyway.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.321, sarcastic: 0.679}\n",
      "Works out of the box—once you buy the missing parts.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.003, sarcastic: 0.997}\n",
      "Crystal-clear display—if you enjoy fog.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.000, sarcastic: 1.000}\n",
      "Fast charging—percentages move at the speed of drama.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.005, sarcastic: 0.995}\n",
      "Kid-friendly app—my inner child cried.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.003, sarcastic: 0.997}\n",
      "Five-star dining—the bill, not the food.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.008, sarcastic: 0.992}\n",
      "The map is so accurate—it led me straight to nowhere.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.007, sarcastic: 0.993}\n",
      "Bluetooth range is impressive—if you stand exactly next to it.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.000, sarcastic: 1.000}\n",
      "Build quality feels solid—like a brick with buttons.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.000, sarcastic: 1.000}\n",
      "The tutorial is intuitive—after the third reread.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.013, sarcastic: 0.987}\n",
      "Sleek interface—hides the settings you actually need.\n",
      "  -> pred: sarcastic | probs: {non-sarcastic: 0.004, sarcastic: 0.996}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "trainer.model.eval()\n",
    "id2label = {0: \"non-sarcastic\", 1: \"sarcastic\"}\n",
    "\n",
    "texts = [\n",
    "\"Perfect for minimalists—comes without the features I actually needed.\",\n",
    "\"Seamless connectivity—disconnects right before you hit connect.\",\n",
    "\"Smells like premium—probably the plastic melting.\",\n",
    "\"Auto-save works great—saves everything except my progress.\",\n",
    "\"Compact design—especially the battery life.\",\n",
    "\"Truly hands-free—because it never responds to touch.\",\n",
    "\"Ergonomic keyboard—if your hands are shaped like question marks.\",\n",
    "\"Water-resistant—tears only, not rain.\",\n",
    "\"Delivers overnight—just not the same night as the order.\",\n",
    "\"Top-tier security—no one, including me, can log in.\",\n",
    "\"Voice assistant understands me—when I say nothing.\",\n",
    "\"The update improved everything—by making sure nothing opens.\",\n",
    "\"Room with natural light—after the sun bounces off the parking lot.\",\n",
    "\"Noise isolation is superb—I couldn’t hear the music at all.\",\n",
    "\"Lag-free gaming—because the game never starts.\",\n",
    "\"Travel pillow so comfy—I stayed awake the entire flight.\",\n",
    "\"Self-cleaning oven—burnt everything to a crisp, problem solved.\",\n",
    "\"Eco mode is powerful—saves energy by not working.\",\n",
    "\"Generous portions—of disappointment.\",\n",
    "\"Shockproof case—phone fainted anyway.\",\n",
    "\"Works out of the box—once you buy the missing parts.\",\n",
    "\"Crystal-clear display—if you enjoy fog.\",\n",
    "\"Fast charging—percentages move at the speed of drama.\",\n",
    "\"Kid-friendly app—my inner child cried.\",\n",
    "\"Five-star dining—the bill, not the food.\",\n",
    "\"The map is so accurate—it led me straight to nowhere.\",\n",
    "\"Bluetooth range is impressive—if you stand exactly next to it.\",\n",
    "\"Build quality feels solid—like a brick with buttons.\",\n",
    "\"The tutorial is intuitive—after the third reread.\",\n",
    "\"Sleek interface—hides the settings you actually need.\"\n",
    "]\n",
    "\n",
    "enc = tok(texts, padding=True, truncation=True, max_length=192, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = trainer.model(**{k: v.to(trainer.model.device) for k, v in enc.items()}).logits\n",
    "probs = F.softmax(logits, dim=-1)\n",
    "pred_ids = probs.argmax(-1).tolist()\n",
    "\n",
    "for t, pid, p in zip(texts, pred_ids, probs.tolist()):\n",
    "    print(f\"{t}\\n  -> pred: {id2label[pid]} | probs: {{non-sarcastic: {p[0]:.3f}, sarcastic: {p[1]:.3f}}}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbc4a624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36_16_R1D5KMCO7KVUGQ\\t\"This band is like sooooooo deep. Like Chester Bennington, I am a tortured artist; one too complex and intelligent to be understood by people who don't watch MTV or TRL. That's why I like MTV, because it caters to head-strong anti-mainstream rebels such as myself.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;STARS&gt;1.0&lt;/STARS&gt;\\n&lt;TITLE&gt;Not even worth finishing...&lt;/TITLE&gt;\\n&lt;DATE&gt;December 6, 2008&lt;/DATE&gt;\\n&lt;AUTHOR&gt;A. CLARK&lt;/AUTHOR&gt;\\n&lt;PRODUCT&gt;Dead Until Dark (Sookie Stackhouse / Southern Vampire Mysteries, No. 1) (Mass Market Paperback)&lt;/PRODUCT&gt;\\n&lt;REVIEW&gt;\\nFirst of all, apologies to all of you who are huge fans of this series of books.  I'm sure you'll hate this review, but remember, this is just one person's opinion.\\n \\n I was drawn to this series due to all of the press it's been receiving lately, and also because I'm up for a good, escapist vampire novel now and then.  I actually bought the whole box set when it came out recently, but am putting my review here (instead of with the boxed set) because I didn't even get past this first book.\\n \\n The book did not hold my interest at all, and believe me, I tried to like it.  I've been attempting to figure out what the problem is.  It's not the setting; I was born in Louisiana, so the setting was one of the attractions of the book.  It's not the overall, view-from-30,000-feet story; that was fine.  So what was it?\\n \\n I'd have to say it was more structural than anything else, for lack of a better word.  I found Ms. Harris' writing to be on par with what an average ninth grader might produce.  The characters, even the main ones, were a bit on the superficial side and weren't really fully developed.  The plot details were quite boring, not engaging at all.  The love scenes were a bit cringe-worthy, reminiscent of scenes from poorly executed smut novels (i.e. just as with smut novels, these parts struck me as nothing more than a fantasy on the part of the author).\\n \\n Overall, the simple fact that I found the book disappointing *IS* the most disappointing part.  That is, if I hadn't had such high hopes, it wouldn't be such a let down.  The story and characters had oodles of potential.\\n&lt;/REVIEW&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;STARS&gt;5.0&lt;/STARS&gt;\\n&lt;TITLE&gt;A series you just have to bite into...&lt;/TITLE&gt;\\n&lt;DATE&gt;August 18, 2009&lt;/DATE&gt;\\n&lt;AUTHOR&gt;CoffeeGurl&lt;/AUTHOR&gt;\\n&lt;PRODUCT&gt;True Blood: The Complete Second Season (HBO Series) (DVD)&lt;/PRODUCT&gt;\\n&lt;REVIEW&gt;\\nI have been a major Sookie Stackhouse fan for years.  I began reading Charlaine Harris's series, then called the Southern Vampire Mysteries, since before book four came out, and have read them all in order.  I was puzzled when I found out that HBO was going to make a TV adaptation of it.  Why this particular series?  Why not Laurell K. Hamilton's Anita Blake series?  (It would have been suitable, what with all of the sex and all.)  There were others as well, like Kelley Armstrong's Women of the Otherworld and MaryJanice Davidson's Queen Betsy series -- all of which have the erotic tones that HBO would have loved.  So why this book series?  Now I know why, but more on that later.\\n \\n I very much enjoyed season one.  It was very faithful to Dead Until Dark, except that small characters like Tara and Lafayette were expanded, and you get everyone's point of view, not just Sookie's.  Also, Bill has more depth here, and you see things from his point of view, and you understand him better.  Other storylines were added, like the emphasis on \"V\" addiction, which makes sense.  Season two has taken things to a whole other level and I love it so far.  I can't wait for the blu-ray release!  From the very beginning, the show has very sexually explicit scenes, most of which centered on Jason's exploits, and some violence as well, with a great deal of emphasis to vampire hatred as the new form of southern racism/segregation.  Season two takes things further, with gore and horror replacing the sex (there's still plenty of it though), and the fledging out of characters like Eric, Tara and Lafayette (whose death does not happen in the TV series).   MaryAnn is the mysterious creature that makes a brief appearance in Living Dead in Dallas, but is expanded on the TV version to the point that she almost takes over the entire show.  Jessica, Bill's \"daughter,\" puzzled me at first.  What's the purpose to this character?  But I like her now, especially after Hoyt becomes her love interest.  And I love the emphasis on vampire makers, like Lorena and Godric, the latter of whom moved me almost to tears in the last episode that he's in (plus, the actor who plays him is totally hot).  I don't want to ruin it for people who don't have HBO and have to wait for the DVD or blu-ray release, but, in spite of the departures from the books, it's better than season one.  \\n \\n The actors are great.  Ann Paquin has grown on me as Sookie, British hottie Stephen Moyer is wonderful as Bill, and I finally like Alexander Skarsgard as everyone's favorite vampire bad boy Eric.  I am also enjoying Sam Trammel (Sam Merlotte), Rutina Wesley (Tara), Nelsan Ellis (Lafayette), Michelle Forbes (MaryAnn Forester) and Ryan Kwatten (Jason Stackhouse).   I am also enjoying the actors who play Andy Belleflour and Hoyt for the comic relief they supply.  (Andy is hilarious as the drunken out-of-work cop who witnesses the orgies and general odd behavior and no one believes him.)  All in all, if you're a big fan of the books, then you won't want to miss this show.  No boring moments throughout the hour-long series.  I cannot wait for season three and season two is not even over yet!  And I see why HBO decided to adapt this particular book series.  They must've seen the potential for character development and the southern setting on the small screen.  Great job!\\n \\n&lt;/REVIEW&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;STARS&gt;3.0&lt;/STARS&gt;\\n&lt;TITLE&gt;Warning: Instructions are incomplete!&lt;/TITLE&gt;\\n&lt;DATE&gt;March 26, 2008&lt;/DATE&gt;\\n&lt;AUTHOR&gt;RunDown&lt;/AUTHOR&gt;\\n&lt;PRODUCT&gt;Knitting With Dog Hair: Better A Sweater From A Dog You Know and Love Than From  A Sheep You'll Never Meet (Paperback)&lt;/PRODUCT&gt;\\n&lt;REVIEW&gt;\\nI must say that I was initially excited about this book. Knitting with dog hair seems like one of those ideas that every pet-owning, recycling, energy-conscious responsible human being should subscribe to. However, one little thing you should be aware of before you get this book. You have to REMOVE the hair from the dog BEFORE you knit. I really wish I had been told this before I started. Sure Scout makes a great hat, but it's really embarrassing if you are walking down the street, wearing your admittedly very stylish chapeau, and the hat pees down the back of your neck. Believe me, after the sixth or seventh time that happened I realized there was something wrong.\\n \\n Fortunately Scout is getting old and struggles less and less each time I wear him and has learned to thrash his legs when he needs to be let down to \"do his business\" (although that causes problems, too, I'll have to get a book about how to knit bandages from mouse hair next). However, I've been thinking about a pair of socks and I'm pretty sure the knitting techniques will be similar, but my cats Snookums and Woogy seem to get very edgy whenever I pick up my razor.\\n&lt;/REVIEW&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;STARS&gt;1.0&lt;/STARS&gt;\\n&lt;TITLE&gt;Husband A Huge Crook, She,: Bitter and Paranoid.&lt;/TITLE&gt;\\n&lt;DATE&gt;January 9, 2008&lt;/DATE&gt;\\n&lt;AUTHOR&gt;Read to Think \"Read To Think\"&lt;/AUTHOR&gt;\\n&lt;PRODUCT&gt;Target: Caught in the Crosshairs of Bill and Hillary Clinton (Hardcover)&lt;/PRODUCT&gt;\\n&lt;REVIEW&gt;\\nHer Husband embezzled so much money, that he would rather kill himself rather than face his crime.  So She decides to go to Oval Office to get a job.  Imagine what the Clinton enemies would have said if Clinton had given a government job to the wife of a huge fundraiser who was a convicted felon?\\n \\n The tone of her book is just blaming and bitter.  Lie down with swine my dear get covered in Mud.\\n \\n That said, Clinton should never be forgiven for betraying the people who believed in him, for cheap and lurid sex.\\n \\n Because of his MonicaGate, we now have to pay with 8 years of the evilest President since Nixon.  Thanks Bill\\n&lt;/REVIEW&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>&lt;STARS&gt;5.0&lt;/STARS&gt;\\n&lt;TITLE&gt;Exactly what I expected&lt;/TITLE&gt;\\n&lt;DATE&gt;June 30, 2010&lt;/DATE&gt;\\n&lt;AUTHOR&gt;J. S. Dayley&lt;/AUTHOR&gt;\\n&lt;PRODUCT&gt;LEATHER MESH GLOVES MOTORCYCLE BIKE GLOVE Black (Apparel)&lt;/PRODUCT&gt;\\n&lt;REVIEW&gt;\\nI really like the reviews that say \"my motorcycle safety class guy said that the best gloves have seams on the outside.\"  Guess what?  These are not the best gloves money can buy.  They are cheap and effective.\\n Same thing about not being able to pick up a quarter off the ground.  That takes me a couple tries with my bare hands.\\n If you want gloves that are by themselves comfortable at all times and in all weather, really durable, maximum protection, dexterity feels better than your bare hands, etc., then you're gonna have to spend $300.00.  (btw, if you own $300 gloves and aren't some kind of professional racer or a retired millionaire out with your wife on a six month Goldwing tour of the US, you're just a sucker.  And if you are one of those two, you're awesome).\\n I do apreciate the comments about them running small.  I got one size up from my usual and they're just a little big.  Really they're just perfect b/c I like to put a pair of $1 knit gloves underneath for weather versatility during the day.\\n The gloves were a little itchy when I first wore them (without my 2nd pair), but that quickly wore off.  With the gloves under, they're SUPER comfortable.  The grip is perfect.  Also love the big knuckle pads.  I get hit with more rocks to my hands than you would believe.\\n All-in-all, for $15 this is a great pair of gloves.\\n&lt;/REVIEW&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>35_12_R2BHAO9XCM3FNL\\t\"With a motley assortment of irreedemable losers and a poorly constructed and boring plot, the reading of this book is only slightly more pleasurable than being poked in the eye with a sharp stick.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>&lt;STARS&gt;1.0&lt;/STARS&gt;\\n&lt;TITLE&gt;this. sucked. bad.&lt;/TITLE&gt;\\n&lt;DATE&gt;July 14, 2010&lt;/DATE&gt;\\n&lt;AUTHOR&gt;dana l. copeland&lt;/AUTHOR&gt;\\n&lt;PRODUCT&gt;The Particular Sadness of Lemon Cake: A Novel (Kindle Edition)&lt;/PRODUCT&gt;\\n&lt;REVIEW&gt;\\none word: punctuation. ok, folks heres the deal: if you enjoy reading books where there are NO QUOTATION MARKS and punctuation such as that, then go ahead, be my guest. if you happen to be SANE, then you would agree with me when i say this: it is thuroughly impossible to read a book when you cant tell who the heck is talking. what idiot translated this?! oh, and if you happen to like other things too, like, say, a good, interesting, or mildly understandable plot, then youre out of luck. god, the people around here.\\n&lt;/REVIEW&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>&lt;STARS&gt;1.0&lt;/STARS&gt;\\n&lt;TITLE&gt;Charming story, had it not been written by Austen...&lt;/TITLE&gt;\\n&lt;DATE&gt;June 18, 1999&lt;/DATE&gt;\\n&lt;AUTHOR&gt;A Customer&lt;/AUTHOR&gt;\\n&lt;PRODUCT&gt;Northanger Abbey (Penguin Classics) (Paperback)&lt;/PRODUCT&gt;\\n&lt;REVIEW&gt;\\nAusten's supposed satire of the gothic novel is tangled up with what would have been the finest fluff of effeminate fiction -- had anyone else written it.  Austen, however, cannot resist sinking her sharp little claws into  naivete, romance, and (of course, this IS Jane Austen) men.  I will say, it  is the only book of hers that I have ever been able to finish. No one  would want to be quite as stupid as poor Catherine, but we've all been  naive.  Personally, I envy Catherine the ability to be so pure and trusting  with the object of her affection -- as jaded and overeducated a modern  woman as I am, I find myself reading the story with no feeling so strong as  a wish that (after closely and cynically examining him) I could meet a man  with whom I felt free to admire his perfections and flaws as the finest in  the world!  (I'm sure there's one out there.)  I'm sure Miss Austen would  find this proof that I am as contemptibly stupid as Catherine, but when we  kill our inner innocent completely, then we have made life unworth living,  and I pity all the people with whom we live and work. The book would be  much better if it didn't dawdle with condemning feminine sweetness &amp;amp;  innocence &amp;amp; male behavior's apparently universal (to Austen)  unacceptability, particularly in tarring them all with the same brush.  It  would be far better if bereft of the perfunctorily &amp;quot;happy ending&amp;quot;  which is treated in such a way that love and marriage wind up reeking of as  much of Austen's contempt to at least the same degree as Mrs. Radcliffe's  literary crimes. If you want to see this story the way it should be, the  way it's funny, check out the movie (an episode of Masterpiece Theater).   If you want to slurp latte in a windowless cafe and paint your nails black,  buy the whole Jane Austen collection!\\n&lt;/REVIEW&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>8_13_RM8RP4OZP12D3\\t\"This tank is great for clearing out the undead. Class 3 outbreak? Zombies around every corner? No problem if you have this tank. With its confortable passanger space and great sniper area on the roof, you will be ready to take down a mob of flesh-starved zombies. If you order the gps link-up with the official Badonkadonk Ion Cannon in orbit, you might even clear the infected area all by yourself (service is extra. $19.99 customer service on the Ion Cannon.) Killer sound, too, so that you can rekill to your favorite music. It has a loudspeaker outside so that the enemy can die to the sound of great music (and not each other's moans.) Overall its a very good tank. But the color selection could be better...\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1368 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              text\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  36_16_R1D5KMCO7KVUGQ\\t\"This band is like sooooooo deep. Like Chester Bennington, I am a tortured artist; one too complex and intelligent to be understood by people who don't watch MTV or TRL. That's why I like MTV, because it caters to head-strong anti-mainstream rebels such as myself.\"\n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       <STARS>1.0</STARS>\\n<TITLE>Not even worth finishing...</TITLE>\\n<DATE>December 6, 2008</DATE>\\n<AUTHOR>A. CLARK</AUTHOR>\\n<PRODUCT>Dead Until Dark (Sookie Stackhouse / Southern Vampire Mysteries, No. 1) (Mass Market Paperback)</PRODUCT>\\n<REVIEW>\\nFirst of all, apologies to all of you who are huge fans of this series of books.  I'm sure you'll hate this review, but remember, this is just one person's opinion.\\n \\n I was drawn to this series due to all of the press it's been receiving lately, and also because I'm up for a good, escapist vampire novel now and then.  I actually bought the whole box set when it came out recently, but am putting my review here (instead of with the boxed set) because I didn't even get past this first book.\\n \\n The book did not hold my interest at all, and believe me, I tried to like it.  I've been attempting to figure out what the problem is.  It's not the setting; I was born in Louisiana, so the setting was one of the attractions of the book.  It's not the overall, view-from-30,000-feet story; that was fine.  So what was it?\\n \\n I'd have to say it was more structural than anything else, for lack of a better word.  I found Ms. Harris' writing to be on par with what an average ninth grader might produce.  The characters, even the main ones, were a bit on the superficial side and weren't really fully developed.  The plot details were quite boring, not engaging at all.  The love scenes were a bit cringe-worthy, reminiscent of scenes from poorly executed smut novels (i.e. just as with smut novels, these parts struck me as nothing more than a fantasy on the part of the author).\\n \\n Overall, the simple fact that I found the book disappointing *IS* the most disappointing part.  That is, if I hadn't had such high hopes, it wouldn't be such a let down.  The story and characters had oodles of potential.\\n</REVIEW>\n",
       "2     <STARS>5.0</STARS>\\n<TITLE>A series you just have to bite into...</TITLE>\\n<DATE>August 18, 2009</DATE>\\n<AUTHOR>CoffeeGurl</AUTHOR>\\n<PRODUCT>True Blood: The Complete Second Season (HBO Series) (DVD)</PRODUCT>\\n<REVIEW>\\nI have been a major Sookie Stackhouse fan for years.  I began reading Charlaine Harris's series, then called the Southern Vampire Mysteries, since before book four came out, and have read them all in order.  I was puzzled when I found out that HBO was going to make a TV adaptation of it.  Why this particular series?  Why not Laurell K. Hamilton's Anita Blake series?  (It would have been suitable, what with all of the sex and all.)  There were others as well, like Kelley Armstrong's Women of the Otherworld and MaryJanice Davidson's Queen Betsy series -- all of which have the erotic tones that HBO would have loved.  So why this book series?  Now I know why, but more on that later.\\n \\n I very much enjoyed season one.  It was very faithful to Dead Until Dark, except that small characters like Tara and Lafayette were expanded, and you get everyone's point of view, not just Sookie's.  Also, Bill has more depth here, and you see things from his point of view, and you understand him better.  Other storylines were added, like the emphasis on \"V\" addiction, which makes sense.  Season two has taken things to a whole other level and I love it so far.  I can't wait for the blu-ray release!  From the very beginning, the show has very sexually explicit scenes, most of which centered on Jason's exploits, and some violence as well, with a great deal of emphasis to vampire hatred as the new form of southern racism/segregation.  Season two takes things further, with gore and horror replacing the sex (there's still plenty of it though), and the fledging out of characters like Eric, Tara and Lafayette (whose death does not happen in the TV series).   MaryAnn is the mysterious creature that makes a brief appearance in Living Dead in Dallas, but is expanded on the TV version to the point that she almost takes over the entire show.  Jessica, Bill's \"daughter,\" puzzled me at first.  What's the purpose to this character?  But I like her now, especially after Hoyt becomes her love interest.  And I love the emphasis on vampire makers, like Lorena and Godric, the latter of whom moved me almost to tears in the last episode that he's in (plus, the actor who plays him is totally hot).  I don't want to ruin it for people who don't have HBO and have to wait for the DVD or blu-ray release, but, in spite of the departures from the books, it's better than season one.  \\n \\n The actors are great.  Ann Paquin has grown on me as Sookie, British hottie Stephen Moyer is wonderful as Bill, and I finally like Alexander Skarsgard as everyone's favorite vampire bad boy Eric.  I am also enjoying Sam Trammel (Sam Merlotte), Rutina Wesley (Tara), Nelsan Ellis (Lafayette), Michelle Forbes (MaryAnn Forester) and Ryan Kwatten (Jason Stackhouse).   I am also enjoying the actors who play Andy Belleflour and Hoyt for the comic relief they supply.  (Andy is hilarious as the drunken out-of-work cop who witnesses the orgies and general odd behavior and no one believes him.)  All in all, if you're a big fan of the books, then you won't want to miss this show.  No boring moments throughout the hour-long series.  I cannot wait for season three and season two is not even over yet!  And I see why HBO decided to adapt this particular book series.  They must've seen the potential for character development and the southern setting on the small screen.  Great job!\\n \\n</REVIEW>\n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   <STARS>3.0</STARS>\\n<TITLE>Warning: Instructions are incomplete!</TITLE>\\n<DATE>March 26, 2008</DATE>\\n<AUTHOR>RunDown</AUTHOR>\\n<PRODUCT>Knitting With Dog Hair: Better A Sweater From A Dog You Know and Love Than From  A Sheep You'll Never Meet (Paperback)</PRODUCT>\\n<REVIEW>\\nI must say that I was initially excited about this book. Knitting with dog hair seems like one of those ideas that every pet-owning, recycling, energy-conscious responsible human being should subscribe to. However, one little thing you should be aware of before you get this book. You have to REMOVE the hair from the dog BEFORE you knit. I really wish I had been told this before I started. Sure Scout makes a great hat, but it's really embarrassing if you are walking down the street, wearing your admittedly very stylish chapeau, and the hat pees down the back of your neck. Believe me, after the sixth or seventh time that happened I realized there was something wrong.\\n \\n Fortunately Scout is getting old and struggles less and less each time I wear him and has learned to thrash his legs when he needs to be let down to \"do his business\" (although that causes problems, too, I'll have to get a book about how to knit bandages from mouse hair next). However, I've been thinking about a pair of socks and I'm pretty sure the knitting techniques will be similar, but my cats Snookums and Woogy seem to get very edgy whenever I pick up my razor.\\n</REVIEW>\n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 <STARS>1.0</STARS>\\n<TITLE>Husband A Huge Crook, She,: Bitter and Paranoid.</TITLE>\\n<DATE>January 9, 2008</DATE>\\n<AUTHOR>Read to Think \"Read To Think\"</AUTHOR>\\n<PRODUCT>Target: Caught in the Crosshairs of Bill and Hillary Clinton (Hardcover)</PRODUCT>\\n<REVIEW>\\nHer Husband embezzled so much money, that he would rather kill himself rather than face his crime.  So She decides to go to Oval Office to get a job.  Imagine what the Clinton enemies would have said if Clinton had given a government job to the wife of a huge fundraiser who was a convicted felon?\\n \\n The tone of her book is just blaming and bitter.  Lie down with swine my dear get covered in Mud.\\n \\n That said, Clinton should never be forgiven for betraying the people who believed in him, for cheap and lurid sex.\\n \\n Because of his MonicaGate, we now have to pay with 8 years of the evilest President since Nixon.  Thanks Bill\\n</REVIEW>\n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ...\n",
       "1363                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              <STARS>5.0</STARS>\\n<TITLE>Exactly what I expected</TITLE>\\n<DATE>June 30, 2010</DATE>\\n<AUTHOR>J. S. Dayley</AUTHOR>\\n<PRODUCT>LEATHER MESH GLOVES MOTORCYCLE BIKE GLOVE Black (Apparel)</PRODUCT>\\n<REVIEW>\\nI really like the reviews that say \"my motorcycle safety class guy said that the best gloves have seams on the outside.\"  Guess what?  These are not the best gloves money can buy.  They are cheap and effective.\\n Same thing about not being able to pick up a quarter off the ground.  That takes me a couple tries with my bare hands.\\n If you want gloves that are by themselves comfortable at all times and in all weather, really durable, maximum protection, dexterity feels better than your bare hands, etc., then you're gonna have to spend $300.00.  (btw, if you own $300 gloves and aren't some kind of professional racer or a retired millionaire out with your wife on a six month Goldwing tour of the US, you're just a sucker.  And if you are one of those two, you're awesome).\\n I do apreciate the comments about them running small.  I got one size up from my usual and they're just a little big.  Really they're just perfect b/c I like to put a pair of $1 knit gloves underneath for weather versatility during the day.\\n The gloves were a little itchy when I first wore them (without my 2nd pair), but that quickly wore off.  With the gloves under, they're SUPER comfortable.  The grip is perfect.  Also love the big knuckle pads.  I get hit with more rocks to my hands than you would believe.\\n All-in-all, for $15 this is a great pair of gloves.\\n</REVIEW>\n",
       "1364                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  35_12_R2BHAO9XCM3FNL\\t\"With a motley assortment of irreedemable losers and a poorly constructed and boring plot, the reading of this book is only slightly more pleasurable than being poked in the eye with a sharp stick.\"\n",
       "1365                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <STARS>1.0</STARS>\\n<TITLE>this. sucked. bad.</TITLE>\\n<DATE>July 14, 2010</DATE>\\n<AUTHOR>dana l. copeland</AUTHOR>\\n<PRODUCT>The Particular Sadness of Lemon Cake: A Novel (Kindle Edition)</PRODUCT>\\n<REVIEW>\\none word: punctuation. ok, folks heres the deal: if you enjoy reading books where there are NO QUOTATION MARKS and punctuation such as that, then go ahead, be my guest. if you happen to be SANE, then you would agree with me when i say this: it is thuroughly impossible to read a book when you cant tell who the heck is talking. what idiot translated this?! oh, and if you happen to like other things too, like, say, a good, interesting, or mildly understandable plot, then youre out of luck. god, the people around here.\\n</REVIEW>\n",
       "1366                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             <STARS>1.0</STARS>\\n<TITLE>Charming story, had it not been written by Austen...</TITLE>\\n<DATE>June 18, 1999</DATE>\\n<AUTHOR>A Customer</AUTHOR>\\n<PRODUCT>Northanger Abbey (Penguin Classics) (Paperback)</PRODUCT>\\n<REVIEW>\\nAusten's supposed satire of the gothic novel is tangled up with what would have been the finest fluff of effeminate fiction -- had anyone else written it.  Austen, however, cannot resist sinking her sharp little claws into  naivete, romance, and (of course, this IS Jane Austen) men.  I will say, it  is the only book of hers that I have ever been able to finish. No one  would want to be quite as stupid as poor Catherine, but we've all been  naive.  Personally, I envy Catherine the ability to be so pure and trusting  with the object of her affection -- as jaded and overeducated a modern  woman as I am, I find myself reading the story with no feeling so strong as  a wish that (after closely and cynically examining him) I could meet a man  with whom I felt free to admire his perfections and flaws as the finest in  the world!  (I'm sure there's one out there.)  I'm sure Miss Austen would  find this proof that I am as contemptibly stupid as Catherine, but when we  kill our inner innocent completely, then we have made life unworth living,  and I pity all the people with whom we live and work. The book would be  much better if it didn't dawdle with condemning feminine sweetness &amp;  innocence &amp; male behavior's apparently universal (to Austen)  unacceptability, particularly in tarring them all with the same brush.  It  would be far better if bereft of the perfunctorily &quot;happy ending&quot;  which is treated in such a way that love and marriage wind up reeking of as  much of Austen's contempt to at least the same degree as Mrs. Radcliffe's  literary crimes. If you want to see this story the way it should be, the  way it's funny, check out the movie (an episode of Masterpiece Theater).   If you want to slurp latte in a windowless cafe and paint your nails black,  buy the whole Jane Austen collection!\\n</REVIEW>\n",
       "1367                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               8_13_RM8RP4OZP12D3\\t\"This tank is great for clearing out the undead. Class 3 outbreak? Zombies around every corner? No problem if you have this tank. With its confortable passanger space and great sniper area on the roof, you will be ready to take down a mob of flesh-starved zombies. If you order the gps link-up with the official Badonkadonk Ion Cannon in orbit, you might even clear the infected area all by yourself (service is extra. $19.99 customer service on the Ion Cannon.) Killer sound, too, so that you can rekill to your favorite music. It has a loudspeaker outside so that the enemy can die to the sound of great music (and not each other's moans.) Overall its a very good tank. But the color selection could be better...\"\n",
       "\n",
       "[1368 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)  # no truncation\n",
    "display(df_train[['text']])                   # or: print(df_test[['text']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eb3cb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_11_r1o7rldlvicklm</td>\n",
       "      <td>&lt;STARS&gt;5.0&lt;/STARS&gt;\\n&lt;TITLE&gt;Deeply Moved&lt;/TITLE&gt;\\n&lt;DATE&gt;July 7, 2009&lt;/DATE&gt;\\n&lt;AUTHOR&gt;Alan E. Schmidt \"Monkey head\"&lt;/AUTHOR&gt;\\n&lt;PRODUCT&gt;Lines, Vines and Trying Times (Audio CD)&lt;/PRODUCT&gt;\\n&lt;REVIEW&gt;\\nI can not believe my eyes, or my ears.... The Jonas Brothers have once again blessed the world. These tunes are exactly what my melody starved soul needed. I was this close to losing my sanity and being unable to perform life's basic functions of walking, talking, and blinking. Thank heavens the release date was not pushed back. \\n \\n I am concerned that the stereo in Mom's 86 Yugo can do this CD justice. Maybe if I jerry rig the home speakers and put them in the back seat I can gain some respect. Some Jonas Brothers RESPECT... It is essential that the music be loud for me... It has to penetrate the court mandated padded helmet I must wear when I venture outdoors. It does not look stupid however, I hand drew little skulls all over it to give it the \"cool factor\". \\n \\n Just yesterday I personally experienced the Jonas Brothers touch two more lives. I was on my way to pick up Mom from the colon cleansing clinic when I was stopped at a red light. Of course I had my new Jonas Bros music at maximum level with the Yugo's windows completely lowered. The two girls in the car next to me were crying. I did not see them at first since my peripheral vision is not the best in my padded helmet. The Jonas Bros had not only awakened their deep seated emotions but it had also stimulated their dormant humor senses. They were laughing uncontrollably. I know it was the Jonas Bros because the crying laughing ladies were looking directly toward me in Mom's Yugo. I waved and winked but only generated more tears from these lovely ladies. \\n \\n I believe that a wise career move for the Jonas Bros would be a multi state penetentiary concert tour. Kind of like Johnny Cash did way back in the day. Their music would definetely help rehabilitate some of those thugs. Don't you worry about their safety... the Jonas Bros are some pretty tough looking dudes. Look at the CD cover. I would not want to meet them in a dark alley, even with my padded helmet on. I know in my heart that the Jonas Bros will be very popular among the prison system population. Like female entertainers at a bachelor party.... Everyone cheering them on and wishing for some alone time with them... to \"talk about life\".. \\n \\n I will need to order myself a Jonas Bros purity ring soon. I will wear it proudly just like my idols. Afterall, I have been getting a lot of female attention lately. (mostly stares). I need to send out a message. Back off you laughing flirtatious ladies. I am saving myself for someone special. \\n \\n Oh my lovely Jonas Brothers, Please don't make me wait this long again for another CD. Look for me at all your concerts. I will be the one in the padded helmet. The one with all the little skulls drawn on it.\\n&lt;/REVIEW&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>ir_10_11_r1o7rldlvicklm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_18_r30tk050962dzv</td>\n",
       "      <td>&lt;STARS&gt;1.0&lt;/STARS&gt;\\n&lt;TITLE&gt;Farce as tragedy&lt;/TITLE&gt;\\n&lt;DATE&gt;February 1, 2008&lt;/DATE&gt;\\n&lt;AUTHOR&gt;N. Ravitch&lt;/AUTHOR&gt;\\n&lt;PRODUCT&gt;The Bush Tragedy (Hardcover)&lt;/PRODUCT&gt;\\n&lt;REVIEW&gt;\\nJournalist Weisberg here cashes in on the current disgust with George W. Bush by trying to make his disastrous presidency into a tragedy, largely through analogies with Henry V, Winston Churchill, and Woodrow Wilson.  Bush nevertheless remains a frat boy who is pushed up into power by the greed and malevolence of the Republican party.  That is the tragedy -- that a great nation could be hoodwinked into voting for someone not even qualified for local dog catcher. As such the story is a terrible farce.\\n \\n The only real contribution is a good assessment of the much over exaggerated role of Dick Cheney in the formulation of Bush policy.  Cheney remains an evil presence but hardly the power behind the throne.  Bush is stupid but not so stupid as to allow himself to be manipulated.  He above all wanted to exert his own will himself.  His relationship with his father is not at all unusual, except that his father was president.\\n \\n The book relies on half-baked psychological theories and borrowings from the Freud-Bullitt volume on the peculiar personality of Woodrow Wilson.  It is not particularly convincing or useful.  \\n \\n As we prepare to elect yet another president we might at least learn to beware.\\n \\n&lt;/REVIEW&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>ir_10_18_r30tk050962dzv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10_2_r3m2qqalunt0nk</td>\n",
       "      <td>&lt;STARS&gt;1.0&lt;/STARS&gt;\\n&lt;TITLE&gt;Horror and Mortal Terror are Not Your Friends&lt;/TITLE&gt;\\n&lt;DATE&gt;March 31, 2010&lt;/DATE&gt;\\n&lt;AUTHOR&gt;Alex I. Aronowicz \"Very Picky Music Man\"&lt;/AUTHOR&gt;\\n&lt;PRODUCT&gt;Sticky &amp; Sweet Tour [Blu-ray] (Blu-ray)&lt;/PRODUCT&gt;\\n&lt;REVIEW&gt;\\nWhen my friend purchased and forced me to watch this, I had no idea it was a Madonna concert until 30 minutes in.  I was convinced that I was watching a horrifying zombie movie.\\n \\n Madonna 3/4 naked on stage at this point in her life...NO!\\n&lt;/REVIEW&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>ir_10_2_r3m2qqalunt0nk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10_6_r222oq5hmg8iw6</td>\n",
       "      <td>&lt;STARS&gt;1.0&lt;/STARS&gt;\\n&lt;TITLE&gt;Another timely book, Another ridiculous Kindle delay&lt;/TITLE&gt;\\n&lt;DATE&gt;February 7, 2010&lt;/DATE&gt;\\n&lt;AUTHOR&gt;Gary R. Gordon \"Rustang\"&lt;/AUTHOR&gt;\\n&lt;PRODUCT&gt;The Politician: An Insider's Account of John Edwards's Pursuit of the Presidency and the Scandal That Brought Him Down (Hardcover)&lt;/PRODUCT&gt;\\n&lt;REVIEW&gt;\\nDoes the publisher seriously think anyone is going to want to buy and read this book on April 27th? By that time John Edwards will have fathered more love children and spent 2400 more dollars on haircuts! That book will be woefully out of date! Publisher, Amazon -- set a price you can live with and release the Kindle book when you release the hardcover. Geeze these guys are stupid!\\n&lt;/REVIEW&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>ir_10_6_r222oq5hmg8iw6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10_7_r1ixyqnnhr3z0k</td>\n",
       "      <td>&lt;STARS&gt;3.0&lt;/STARS&gt;\\n&lt;TITLE&gt;Not complete without the line....&lt;/TITLE&gt;\\n&lt;DATE&gt;March 8, 2008&lt;/DATE&gt;\\n&lt;AUTHOR&gt;M. MCKNIGHT \"reviewer\"&lt;/AUTHOR&gt;\\n&lt;PRODUCT&gt;Playmobil Security Check Point (Toy)&lt;/PRODUCT&gt;\\n&lt;REVIEW&gt;\\nThis toy would be a lot more realistic with about 350 people standing in line for an average of an hour.  It still makes a nice set with the interrogation room.\\n&lt;/REVIEW&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>ir_10_7_r1ixyqnnhr3z0k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>9_2_r3c76rics2pw87</td>\n",
       "      <td>&lt;STARS&gt;4.0&lt;/STARS&gt;\\n&lt;TITLE&gt;Not the real thing, but quite good&lt;/TITLE&gt;\\n&lt;DATE&gt;February 15, 2009&lt;/DATE&gt;\\n&lt;AUTHOR&gt;Peter Reeve&lt;/AUTHOR&gt;\\n&lt;PRODUCT&gt;Heinz Spotted Dick Sponge Pudding, 10-Ounce Cans (Pack of 6) (Grocery)&lt;/PRODUCT&gt;\\n&lt;REVIEW&gt;\\nThere are at least two known breeds of Spotted Dick (or Spotted Dog, as it was once called).  The one that was a staple of my childhood (English working class) diet is a steamed suet pudding.  It is made from suet, flour, sugar, currants and raisins, and is usually served with treacle.\\n \\n The Heinz canned version is a very different animal, a member of the sponge pudding race, containing no suet.  It is nice enough, and is especially good with English-style custard.  It is tasty, filling and easy to prepare, and its name makes it great fun.\\n \\n But if you are a fan of the Aubrey/Maturin stories and want to eat like them, be warned that this is not the real thing.  The genuine Spotted Dick (or Dog), described in O'Brian's books, is the glorious suet pudding of my youth.\\n [PeterReeve]\\n \\n&lt;/REVIEW&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_9_2_r3c76rics2pw87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>9_3_r3etdjechuq31r</td>\n",
       "      <td>&lt;STARS&gt;4.0&lt;/STARS&gt;\\n&lt;TITLE&gt;It works but isn't gonna change your life.&lt;/TITLE&gt;\\n&lt;DATE&gt;July 14, 2010&lt;/DATE&gt;\\n&lt;AUTHOR&gt;E. Ford&lt;/AUTHOR&gt;\\n&lt;PRODUCT&gt;Rogaine for Men Hair Regrowth Treatment, Easy-to-Use Foam, 2.11-Ounce Cans (Pack of 3) (Health and Beauty)&lt;/PRODUCT&gt;\\n&lt;REVIEW&gt;\\nI have used for the past 6-7 months. For the most part it thickens and I have noticed regrowth in some areas. However these are on the crown and my receding hairline. The only thing is, it slightly grows so you can see very minor growth but nothing ever really comes from it. On the crown of my head I have had a bald spot and only in a very specific area did hair growth occur. Other then that I have noticed increase in thickness and growth in the places I already have hair. If you are in the very early stages of hair loss, I think it would be much more effective. However if you are quite away into it, may be better to look at some other options.\\n&lt;/REVIEW&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_9_3_r3etdjechuq31r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>9_5_r3jqnbitxxn2d</td>\n",
       "      <td>&lt;STARS&gt;5.0&lt;/STARS&gt;\\n&lt;TITLE&gt;A must read book&lt;/TITLE&gt;\\n&lt;DATE&gt;March 16, 2010&lt;/DATE&gt;\\n&lt;AUTHOR&gt;Thomas&lt;/AUTHOR&gt;\\n&lt;PRODUCT&gt;The Scent of Rain and Lightning: A Novel (Hardcover)&lt;/PRODUCT&gt;\\n&lt;REVIEW&gt;\\nThe Scent of Rain and Lightning by Nancy Pickard was the best novel I've read in a long time. The first couple of pages grabbed me--there was no reading half the book before I decided I liked it.  Pickard writes in an easy style about people and life in Kansas, but it could be any rural/ranching setting.  The characters were described so perfectly that I felt like I grew up with them.  This is a murder mystery, but it's definitely not your typical who-done-it.  The plot unfolds gently--no harsh, sharp twists and turns.  It's also a love story and a story of a close-knit family.  It has everything but nothing is contrived; it's all very natural and believable.  I think the best way to describe the book is that it's a gentle, easy story about some ungentle events. I can understand why Pickard has received so many awards. She is a great American author; in my opinion on the same level as Twain and Steinbeck. This book is a MUST READ.\\n&lt;/REVIEW&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_9_5_r3jqnbitxxn2d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>9_7_r86qtgv8ewk93</td>\n",
       "      <td>&lt;STARS&gt;5.0&lt;/STARS&gt;\\n&lt;TITLE&gt;Best Monkey Island game ever.&lt;/TITLE&gt;\\n&lt;DATE&gt;August 24, 2009&lt;/DATE&gt;\\n&lt;AUTHOR&gt;Kevin Derby \"FreeArcade.com\"&lt;/AUTHOR&gt;\\n&lt;PRODUCT&gt;Tales of Monkey Island: Chapter 1 [Game Download] (Software Download)&lt;/PRODUCT&gt;\\n&lt;REVIEW&gt;\\nOk, I am an old time monkey Island game fan.  I have played them all, and I think this is the best one yet.  I like the cartoon like cinematic style, voice acting is great, and the puzzles are (mostly) fair.  We all gather round and play as a family.  Great puzzle solving fun for parents and kids together.\\n \\n The user interface isn't perfect. Dragging Guybrush around with the mouse can be a bit difficult(you can also use the arrow keys on the keyboard), and sometimes the camera angles can be a problem.  Also the lip sync is terrible, which is a little distracting at first. \\n \\n You can subscribe to all 5 episodes at once and get a break on the single episode price(I did).  At this writing, only the first 2 episodes are available, with new ones scheduled monthly.\\n&lt;/REVIEW&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_9_7_r86qtgv8ewk93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>9_8_r3v4u0480fjido</td>\n",
       "      <td>&lt;STARS&gt;5.0&lt;/STARS&gt;\\n&lt;TITLE&gt;So Funny!!&lt;/TITLE&gt;\\n&lt;DATE&gt;December 30, 2009&lt;/DATE&gt;\\n&lt;AUTHOR&gt;Elinor&lt;/AUTHOR&gt;\\n&lt;PRODUCT&gt;Handerpants (Misc.)&lt;/PRODUCT&gt;\\n&lt;REVIEW&gt;\\nI got this as a Christmas present for my brother, and the whole family loved it! They are so funny and a great fun kind of joke.\\n&lt;/REVIEW&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_9_8_r3v4u0480fjido</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1015 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fname  \\\n",
       "0     10_11_r1o7rldlvicklm   \n",
       "1     10_18_r30tk050962dzv   \n",
       "2      10_2_r3m2qqalunt0nk   \n",
       "3      10_6_r222oq5hmg8iw6   \n",
       "4      10_7_r1ixyqnnhr3z0k   \n",
       "...                    ...   \n",
       "1010    9_2_r3c76rics2pw87   \n",
       "1011    9_3_r3etdjechuq31r   \n",
       "1012     9_5_r3jqnbitxxn2d   \n",
       "1013     9_7_r86qtgv8ewk93   \n",
       "1014    9_8_r3v4u0480fjido   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        text  \\\n",
       "0     <STARS>5.0</STARS>\\n<TITLE>Deeply Moved</TITLE>\\n<DATE>July 7, 2009</DATE>\\n<AUTHOR>Alan E. Schmidt \"Monkey head\"</AUTHOR>\\n<PRODUCT>Lines, Vines and Trying Times (Audio CD)</PRODUCT>\\n<REVIEW>\\nI can not believe my eyes, or my ears.... The Jonas Brothers have once again blessed the world. These tunes are exactly what my melody starved soul needed. I was this close to losing my sanity and being unable to perform life's basic functions of walking, talking, and blinking. Thank heavens the release date was not pushed back. \\n \\n I am concerned that the stereo in Mom's 86 Yugo can do this CD justice. Maybe if I jerry rig the home speakers and put them in the back seat I can gain some respect. Some Jonas Brothers RESPECT... It is essential that the music be loud for me... It has to penetrate the court mandated padded helmet I must wear when I venture outdoors. It does not look stupid however, I hand drew little skulls all over it to give it the \"cool factor\". \\n \\n Just yesterday I personally experienced the Jonas Brothers touch two more lives. I was on my way to pick up Mom from the colon cleansing clinic when I was stopped at a red light. Of course I had my new Jonas Bros music at maximum level with the Yugo's windows completely lowered. The two girls in the car next to me were crying. I did not see them at first since my peripheral vision is not the best in my padded helmet. The Jonas Bros had not only awakened their deep seated emotions but it had also stimulated their dormant humor senses. They were laughing uncontrollably. I know it was the Jonas Bros because the crying laughing ladies were looking directly toward me in Mom's Yugo. I waved and winked but only generated more tears from these lovely ladies. \\n \\n I believe that a wise career move for the Jonas Bros would be a multi state penetentiary concert tour. Kind of like Johnny Cash did way back in the day. Their music would definetely help rehabilitate some of those thugs. Don't you worry about their safety... the Jonas Bros are some pretty tough looking dudes. Look at the CD cover. I would not want to meet them in a dark alley, even with my padded helmet on. I know in my heart that the Jonas Bros will be very popular among the prison system population. Like female entertainers at a bachelor party.... Everyone cheering them on and wishing for some alone time with them... to \"talk about life\".. \\n \\n I will need to order myself a Jonas Bros purity ring soon. I will wear it proudly just like my idols. Afterall, I have been getting a lot of female attention lately. (mostly stares). I need to send out a message. Back off you laughing flirtatious ladies. I am saving myself for someone special. \\n \\n Oh my lovely Jonas Brothers, Please don't make me wait this long again for another CD. Look for me at all your concerts. I will be the one in the padded helmet. The one with all the little skulls drawn on it.\\n</REVIEW>   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               <STARS>1.0</STARS>\\n<TITLE>Farce as tragedy</TITLE>\\n<DATE>February 1, 2008</DATE>\\n<AUTHOR>N. Ravitch</AUTHOR>\\n<PRODUCT>The Bush Tragedy (Hardcover)</PRODUCT>\\n<REVIEW>\\nJournalist Weisberg here cashes in on the current disgust with George W. Bush by trying to make his disastrous presidency into a tragedy, largely through analogies with Henry V, Winston Churchill, and Woodrow Wilson.  Bush nevertheless remains a frat boy who is pushed up into power by the greed and malevolence of the Republican party.  That is the tragedy -- that a great nation could be hoodwinked into voting for someone not even qualified for local dog catcher. As such the story is a terrible farce.\\n \\n The only real contribution is a good assessment of the much over exaggerated role of Dick Cheney in the formulation of Bush policy.  Cheney remains an evil presence but hardly the power behind the throne.  Bush is stupid but not so stupid as to allow himself to be manipulated.  He above all wanted to exert his own will himself.  His relationship with his father is not at all unusual, except that his father was president.\\n \\n The book relies on half-baked psychological theories and borrowings from the Freud-Bullitt volume on the peculiar personality of Woodrow Wilson.  It is not particularly convincing or useful.  \\n \\n As we prepare to elect yet another president we might at least learn to beware.\\n \\n</REVIEW>   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               <STARS>1.0</STARS>\\n<TITLE>Horror and Mortal Terror are Not Your Friends</TITLE>\\n<DATE>March 31, 2010</DATE>\\n<AUTHOR>Alex I. Aronowicz \"Very Picky Music Man\"</AUTHOR>\\n<PRODUCT>Sticky & Sweet Tour [Blu-ray] (Blu-ray)</PRODUCT>\\n<REVIEW>\\nWhen my friend purchased and forced me to watch this, I had no idea it was a Madonna concert until 30 minutes in.  I was convinced that I was watching a horrifying zombie movie.\\n \\n Madonna 3/4 naked on stage at this point in her life...NO!\\n</REVIEW>   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <STARS>1.0</STARS>\\n<TITLE>Another timely book, Another ridiculous Kindle delay</TITLE>\\n<DATE>February 7, 2010</DATE>\\n<AUTHOR>Gary R. Gordon \"Rustang\"</AUTHOR>\\n<PRODUCT>The Politician: An Insider's Account of John Edwards's Pursuit of the Presidency and the Scandal That Brought Him Down (Hardcover)</PRODUCT>\\n<REVIEW>\\nDoes the publisher seriously think anyone is going to want to buy and read this book on April 27th? By that time John Edwards will have fathered more love children and spent 2400 more dollars on haircuts! That book will be woefully out of date! Publisher, Amazon -- set a price you can live with and release the Kindle book when you release the hardcover. Geeze these guys are stupid!\\n</REVIEW>   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  <STARS>3.0</STARS>\\n<TITLE>Not complete without the line....</TITLE>\\n<DATE>March 8, 2008</DATE>\\n<AUTHOR>M. MCKNIGHT \"reviewer\"</AUTHOR>\\n<PRODUCT>Playmobil Security Check Point (Toy)</PRODUCT>\\n<REVIEW>\\nThis toy would be a lot more realistic with about 350 people standing in line for an average of an hour.  It still makes a nice set with the interrogation room.\\n</REVIEW>   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...   \n",
       "1010                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   <STARS>4.0</STARS>\\n<TITLE>Not the real thing, but quite good</TITLE>\\n<DATE>February 15, 2009</DATE>\\n<AUTHOR>Peter Reeve</AUTHOR>\\n<PRODUCT>Heinz Spotted Dick Sponge Pudding, 10-Ounce Cans (Pack of 6) (Grocery)</PRODUCT>\\n<REVIEW>\\nThere are at least two known breeds of Spotted Dick (or Spotted Dog, as it was once called).  The one that was a staple of my childhood (English working class) diet is a steamed suet pudding.  It is made from suet, flour, sugar, currants and raisins, and is usually served with treacle.\\n \\n The Heinz canned version is a very different animal, a member of the sponge pudding race, containing no suet.  It is nice enough, and is especially good with English-style custard.  It is tasty, filling and easy to prepare, and its name makes it great fun.\\n \\n But if you are a fan of the Aubrey/Maturin stories and want to eat like them, be warned that this is not the real thing.  The genuine Spotted Dick (or Dog), described in O'Brian's books, is the glorious suet pudding of my youth.\\n [PeterReeve]\\n \\n</REVIEW>   \n",
       "1011                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   <STARS>4.0</STARS>\\n<TITLE>It works but isn't gonna change your life.</TITLE>\\n<DATE>July 14, 2010</DATE>\\n<AUTHOR>E. Ford</AUTHOR>\\n<PRODUCT>Rogaine for Men Hair Regrowth Treatment, Easy-to-Use Foam, 2.11-Ounce Cans (Pack of 3) (Health and Beauty)</PRODUCT>\\n<REVIEW>\\nI have used for the past 6-7 months. For the most part it thickens and I have noticed regrowth in some areas. However these are on the crown and my receding hairline. The only thing is, it slightly grows so you can see very minor growth but nothing ever really comes from it. On the crown of my head I have had a bald spot and only in a very specific area did hair growth occur. Other then that I have noticed increase in thickness and growth in the places I already have hair. If you are in the very early stages of hair loss, I think it would be much more effective. However if you are quite away into it, may be better to look at some other options.\\n</REVIEW>   \n",
       "1012                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               <STARS>5.0</STARS>\\n<TITLE>A must read book</TITLE>\\n<DATE>March 16, 2010</DATE>\\n<AUTHOR>Thomas</AUTHOR>\\n<PRODUCT>The Scent of Rain and Lightning: A Novel (Hardcover)</PRODUCT>\\n<REVIEW>\\nThe Scent of Rain and Lightning by Nancy Pickard was the best novel I've read in a long time. The first couple of pages grabbed me--there was no reading half the book before I decided I liked it.  Pickard writes in an easy style about people and life in Kansas, but it could be any rural/ranching setting.  The characters were described so perfectly that I felt like I grew up with them.  This is a murder mystery, but it's definitely not your typical who-done-it.  The plot unfolds gently--no harsh, sharp twists and turns.  It's also a love story and a story of a close-knit family.  It has everything but nothing is contrived; it's all very natural and believable.  I think the best way to describe the book is that it's a gentle, easy story about some ungentle events. I can understand why Pickard has received so many awards. She is a great American author; in my opinion on the same level as Twain and Steinbeck. This book is a MUST READ.\\n</REVIEW>   \n",
       "1013                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   <STARS>5.0</STARS>\\n<TITLE>Best Monkey Island game ever.</TITLE>\\n<DATE>August 24, 2009</DATE>\\n<AUTHOR>Kevin Derby \"FreeArcade.com\"</AUTHOR>\\n<PRODUCT>Tales of Monkey Island: Chapter 1 [Game Download] (Software Download)</PRODUCT>\\n<REVIEW>\\nOk, I am an old time monkey Island game fan.  I have played them all, and I think this is the best one yet.  I like the cartoon like cinematic style, voice acting is great, and the puzzles are (mostly) fair.  We all gather round and play as a family.  Great puzzle solving fun for parents and kids together.\\n \\n The user interface isn't perfect. Dragging Guybrush around with the mouse can be a bit difficult(you can also use the arrow keys on the keyboard), and sometimes the camera angles can be a problem.  Also the lip sync is terrible, which is a little distracting at first. \\n \\n You can subscribe to all 5 episodes at once and get a break on the single episode price(I did).  At this writing, only the first 2 episodes are available, with new ones scheduled monthly.\\n</REVIEW>   \n",
       "1014                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   <STARS>5.0</STARS>\\n<TITLE>So Funny!!</TITLE>\\n<DATE>December 30, 2009</DATE>\\n<AUTHOR>Elinor</AUTHOR>\\n<PRODUCT>Handerpants (Misc.)</PRODUCT>\\n<REVIEW>\\nI got this as a Christmas present for my brother, and the whole family loved it! They are so funny and a great fun kind of joke.\\n</REVIEW>   \n",
       "\n",
       "      label                    group  \n",
       "0         1  ir_10_11_r1o7rldlvicklm  \n",
       "1         1  ir_10_18_r30tk050962dzv  \n",
       "2         1   ir_10_2_r3m2qqalunt0nk  \n",
       "3         1   ir_10_6_r222oq5hmg8iw6  \n",
       "4         1   ir_10_7_r1ixyqnnhr3z0k  \n",
       "...     ...                      ...  \n",
       "1010      0   reg_9_2_r3c76rics2pw87  \n",
       "1011      0   reg_9_3_r3etdjechuq31r  \n",
       "1012      0    reg_9_5_r3jqnbitxxn2d  \n",
       "1013      0    reg_9_7_r86qtgv8ewk93  \n",
       "1014      0   reg_9_8_r3v4u0480fjido  \n",
       "\n",
       "[1015 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
